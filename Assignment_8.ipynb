{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandhu1585/NLP/blob/main/Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example text data (you can replace this with any larger corpus) text = \"\"\" Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her. [CO5]\n",
        "(i) Build the Transformer Model on above dataset"
      ],
      "metadata": {
        "id": "hzRyR2Xhcay9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq917oipcXZo",
        "outputId": "e5684ee6-4009-4657-9f74-a9b369637dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input ids: tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,  1310,  2576,\n",
            "          3706,  2297, 36032, 17233,    13,  1375,  6151,   284,  3187,   607,\n",
            "         18410,    11,   508,  5615,   287,   262, 16479,    13,  1881,  1110,\n",
            "            11,   607,  2802,  1965,   607,   284,  1011,   257,  7988,   286,\n",
            "         39863,   284,   607, 18410,    13,  1550,   607,   835,   832,   262,\n",
            "         16479,    11,   673,  1138,   257,  1263,  2089, 17481,   508,  2227,\n",
            "           284,  4483,   607,    13]])\n",
            "Loss: 2.5232996940612793\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "text = \"\"\"Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her.\"\"\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "input_ids = tokens['input_ids']\n",
        "\n",
        "print(f\"Tokenized input ids: {input_ids}\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "output = model(input_ids.to(device), labels=input_ids.to(device))\n",
        "loss = output.loss\n",
        "logits = output.logits\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Train the model using 20, 60, 70 epochs"
      ],
      "metadata": {
        "id": "U8SNrfvsd5lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, TrainingArguments, Trainer\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def train_model(num_epochs):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_{num_epochs}_epochs\",\n",
        "        num_train_epochs=num_epochs,\n",
        "        per_device_train_batch_size=1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        save_steps=10,\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    print(f\"Training completed for {num_epochs} epochs.\")\n",
        "\n",
        "train_model(20)\n",
        "train_model(60)\n",
        "train_model(70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "Bcaj16rnejId",
        "outputId": "65344528-beb1-4116-f6de-0a365f756c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 01:05, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.199500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 20 epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 03:00, Epoch 60/60]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.129300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.019800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.028700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.056400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 60 epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 04:03, Epoch 70/70]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.029600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 70 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " (iii) After training, use the model to generate new text by feeding it an initial seed text\n",
        "\n"
      ],
      "metadata": {
        "id": "JgbPwWdpg35-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Once upon a time\"\n",
        "\n",
        "input_ids = tokenizer.encode(seed_text, return_tensors=\"pt\")\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=50,\n",
        "    num_return_sequences=1,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1yHqKjEg4UA",
        "outputId": "c1a1d49c-af17-4673-cfb3-ee01191fcdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods.\n",
            "One day, her mother asked her to take a basket of goodies to her grandmother. On her way to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iv) Experimenting and Improving the Model by large dataset and hyper tune parameter.\n",
        "\n"
      ],
      "metadata": {
        "id": "47Kr2JzhhcLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "text = \"\"\"Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her.\"\"\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "input_ids = tokens['input_ids']\n",
        "\n",
        "attention_mask = tokens.get('attention_mask', torch.ones_like(input_ids))\n",
        "\n",
        "print(f\"Tokenized input ids: {input_ids}\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "output = model(input_ids.to(device), attention_mask=attention_mask.to(device), labels=input_ids.to(device))\n",
        "loss = output.loss\n",
        "logits = output.logits\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "model.eval()\n",
        "generated_text = model.generate(\n",
        "    input_ids.to(device),\n",
        "    max_length=100,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.92,\n",
        "    temperature=0.7,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voZYm8cIhcl_",
        "outputId": "1216ed2c-7328-4fa9-ec43-0959590aa07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input ids: tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,  1310,  2576,\n",
            "          3706,  2297, 36032, 17233,    13,  1375,  6151,   284,  3187,   607,\n",
            "         18410,    11,   508,  5615,   287,   262, 16479,    13,  1881,  1110,\n",
            "            11,   607,  2802,  1965,   607,   284,  1011,   257,  7988,   286,\n",
            "         39863,   284,   607, 18410,    13,  1550,   607,   835,   832,   262,\n",
            "         16479,    11,   673,  1138,   257,  1263,  2089, 17481,   508,  2227,\n",
            "           284,  4483,   607,    13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5232996940612793\n",
            "Generated Text: Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her. As she was passing the basket, she found out that she was a wolf. She ran to her grandmother's house, and said that she needed help to feed her wolf. The\n"
          ]
        }
      ]
    }
  ]
}